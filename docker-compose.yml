version: "3.7"

# ---- common kafka env (MERGEABLE) ----
x-kafka-env: &kafka_env
  KAFKA_ZOOKEEPER_CONNECT: kafka_zookeeper:2181
  KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
  KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
  KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
  KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
  KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
  KAFKA_MIN_INSYNC_REPLICAS: 2

# ---- common kafka container config ----
x-kafka-base: &kafka_base
  image: confluentinc/cp-kafka:7.5.3
  depends_on:
    - kafka_zookeeper
  networks:
    - kafka_network
    - default

services:
  airflow_db:
    image: postgres:16.0
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    logging:
      options:
        max-size: 10m
        max-file: "3"

  airflow_webserver:
    user: "0:0"
    image: apache/airflow:2.9.3
    command: >
      bash -c "
      airflow db migrate &&
      airflow users create --role Admin --username admin --email admin@local --firstname admin --lastname admin --password admin || true &&
      exec airflow webserver
      "

    restart: always
    depends_on:
      - airflow_db
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@airflow_db:5432/${POSTGRES_DB}
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}

    volumes:
      - ./dags:/opt/airflow/dags
      - ./requirements.txt:/opt/airflow/requirements.txt
    ports:
      - "8080:8080"

  airflow_scheduler:
    user: "0:0"
    image: apache/airflow:2.9.3
    command: >
      bash -c "
      exec airflow scheduler
      "
    restart: always
    depends_on:
      - airflow_db
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@airflow_db:5432/${POSTGRES_DB}
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}

    volumes:
      - ./dags:/opt/airflow/dags
      - ./requirements.txt:/opt/airflow/requirements.txt

  kafka_zookeeper:
    image: confluentinc/cp-zookeeper:7.5.3
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: ${ZOOKEEPER_CLIENT_PORT}
      ZOOKEEPER_SERVER_ID: ${ZOOKEEPER_SERVER_ID}
      ZOOKEEPER_SERVERS: kafka_zookeeper:2888:3888
    networks:
      - kafka_network
      - default

  kafka_broker_1:
    <<: *kafka_base
    environment:
      <<: *kafka_env
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:19092,EXTERNAL://0.0.0.0:9092,DOCKER://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka_broker_1:19092,EXTERNAL://localhost:9092,DOCKER://host.docker.internal:29092

  kafka_broker_2:
    <<: *kafka_base
    environment:
      <<: *kafka_env
      KAFKA_BROKER_ID: 2
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:19093,EXTERNAL://0.0.0.0:9093,DOCKER://0.0.0.0:29093
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka_broker_2:19093,EXTERNAL://localhost:9093,DOCKER://host.docker.internal:29093

  kafka_broker_3:
    <<: *kafka_base
    environment:
      <<: *kafka_env
      KAFKA_BROKER_ID: 3
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:19094,EXTERNAL://0.0.0.0:9094,DOCKER://0.0.0.0:29094
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka_broker_3:19094,EXTERNAL://localhost:9094,DOCKER://host.docker.internal:29094

  kafka_connect:
    image: confluentinc/cp-kafka-connect:7.5.3
    ports:
      - "8083:8083"
    depends_on:
      - kafka_broker_1
      - kafka_broker_2
      - kafka_broker_3
    environment:
      CONNECT_BOOTSTRAP_SERVERS: ${CONNECT_BOOTSTRAP_SERVERS}
      CONNECT_REST_PORT: ${CONNECT_REST_PORT}
      CONNECT_GROUP_ID: ${CONNECT_GROUP_ID}
      CONNECT_CONFIG_STORAGE_TOPIC: ${CONNECT_CONFIG_STORAGE_TOPIC}
      CONNECT_OFFSET_STORAGE_TOPIC: ${CONNECT_OFFSET_STORAGE_TOPIC}
      CONNECT_STATUS_STORAGE_TOPIC: ${CONNECT_STATUS_STORAGE_TOPIC}
      CONNECT_KEY_CONVERTER: ${CONNECT_KEY_CONVERTER}
      CONNECT_VALUE_CONVERTER: ${CONNECT_VALUE_CONVERTER}
      CONNECT_INTERNAL_KEY_CONVERTER: ${CONNECT_INTERNAL_KEY_CONVERTER}
      CONNECT_INTERNAL_VALUE_CONVERTER: ${CONNECT_INTERNAL_VALUE_CONVERTER}
      CONNECT_REST_ADVERTISED_HOST_NAME: ${CONNECT_REST_ADVERTISED_HOST_NAME}
      CONNECT_LOG4J_ROOT_LOGLEVEL: ${CONNECT_LOG4J_ROOT_LOGLEVEL}
      CONNECT_LOG4J_LOGGERS: ${CONNECT_LOG4J_LOGGERS}
      CONNECT_PLUGIN_PATH: ${CONNECT_PLUGIN_PATH}
    networks:
      - kafka_network
      - default

  kafka_schema_registry:
    image: confluentinc/cp-schema-registry:7.5.3
    ports:
      - "8081:8081"
    depends_on:
      - kafka_broker_1
      - kafka_broker_2
      - kafka_broker_3
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: ${SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS}
      SCHEMA_REGISTRY_HOST_NAME: ${SCHEMA_REGISTRY_HOST_NAME}
      SCHEMA_REGISTRY_LISTENERS: ${SCHEMA_REGISTRY_LISTENERS}
    networks:
      - kafka_network
      - default

  kafka_ui:
    container_name: kafka-ui-1
    image: provectuslabs/kafka-ui:latest
    ports:
      - "8888:8080"
    depends_on:
      - kafka_broker_1
      - kafka_broker_2
      - kafka_broker_3
      - kafka_schema_registry
      - kafka_connect
    environment:
      KAFKA_CLUSTERS_0_NAME: ${KAFKA_CLUSTERS_0_NAME}
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: ${KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS}
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: ${KAFKA_CLUSTERS_0_SCHEMAREGISTRY}
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: ${KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME}
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: ${KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS}
      DYNAMIC_CONFIG_ENABLED: ${DYNAMIC_CONFIG_ENABLED}
    networks:
      - kafka_network
      - default

  spark_master:
    image: apache/spark:3.5.1
    container_name: spark_master
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.master.Master"]
    ports:
      - "8085:8080"
      - "7077:7077"
    volumes:
      - ./:/home
    networks:
      - default
      - kafka_network

volumes:
  spark_data:

networks:
  kafka_network:
      driver: bridge
  default:
      name: docker_streaming
      external: true
